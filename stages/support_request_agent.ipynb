{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### support request agent\n",
        "\n",
        "Build and deploy a generic support-request agent with order context and user interaction history.\n",
        "\n",
        "Outputs include:\n",
        "- credit recommendation\n",
        "- refund recommendation\n",
        "- draft customer response\n",
        "- past interactions summary\n",
        "- order details summary"
      ],
      "id": "67c1e4f0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "CATALOG = dbutils.widgets.get(\"CATALOG\")\n",
        "LLM_MODEL = dbutils.widgets.get(\"LLM_MODEL\")\n",
        "SUPPORT_AGENT_ENDPOINT_NAME = dbutils.widgets.get(\"SUPPORT_AGENT_ENDPOINT_NAME\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "bc1af022"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.support\")\n",
        "spark.sql(f\"CREATE TABLE IF NOT EXISTS {CATALOG}.support.support_agent_reports (support_request_id STRING, user_id STRING, order_id STRING, request_text STRING, ts TIMESTAMP, agent_response STRING)\")\n",
        "\n",
        "# Backfill-safe schema evolution for existing tables.\n",
        "try:\n",
        "    spark.sql(f\"ALTER TABLE {CATALOG}.support.support_agent_reports ADD COLUMNS (request_text STRING)\")\n",
        "except Exception:\n",
        "    # Column already exists or table metadata already evolved.\n",
        "    pass\n",
        "\n",
        "spark.sql(f\"\"\"\n",
        "CREATE OR REPLACE FUNCTION {CATALOG}.ai.get_order_overview(oid STRING)\n",
        "RETURNS TABLE (\n",
        "  order_id STRING,\n",
        "  location STRING,\n",
        "  items_json STRING,\n",
        "  customer_address STRING,\n",
        "  order_created_ts TIMESTAMP\n",
        ")\n",
        "RETURN\n",
        "  SELECT\n",
        "    order_id,\n",
        "    location,\n",
        "    get_json_object(body, '$.items') AS items_json,\n",
        "    get_json_object(body, '$.customer_addr') AS customer_address,\n",
        "    try_to_timestamp(ts) AS order_created_ts\n",
        "  FROM {CATALOG}.lakeflow.all_events\n",
        "  WHERE order_id = oid AND event_type = 'order_created'\n",
        "  LIMIT 1\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(f\"\"\"\n",
        "CREATE OR REPLACE FUNCTION {CATALOG}.ai.get_order_timing(oid STRING)\n",
        "RETURNS TABLE (\n",
        "  order_id STRING,\n",
        "  order_created_ts TIMESTAMP,\n",
        "  delivered_ts TIMESTAMP,\n",
        "  delivery_duration_minutes FLOAT\n",
        ")\n",
        "RETURN\n",
        "  WITH order_events AS (\n",
        "    SELECT order_id, event_type, try_to_timestamp(ts) AS event_ts\n",
        "    FROM {CATALOG}.lakeflow.all_events\n",
        "    WHERE order_id = oid\n",
        "  )\n",
        "  SELECT\n",
        "    order_id,\n",
        "    MIN(CASE WHEN event_type='order_created' THEN event_ts END) AS order_created_ts,\n",
        "    MAX(CASE WHEN event_type='delivered' THEN event_ts END) AS delivered_ts,\n",
        "    CAST((UNIX_TIMESTAMP(MAX(CASE WHEN event_type='delivered' THEN event_ts END)) - UNIX_TIMESTAMP(MIN(CASE WHEN event_type='order_created' THEN event_ts END))) / 60 AS FLOAT) AS delivery_duration_minutes\n",
        "  FROM order_events\n",
        "  GROUP BY order_id\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(f\"\"\"\n",
        "CREATE OR REPLACE FUNCTION {CATALOG}.ai.get_user_support_history(uid STRING)\n",
        "RETURNS TABLE (\n",
        "  support_request_id STRING,\n",
        "  order_id STRING,\n",
        "  ts TIMESTAMP,\n",
        "  agent_response STRING\n",
        ")\n",
        "RETURN\n",
        "  SELECT support_request_id, order_id, ts, agent_response\n",
        "  FROM {CATALOG}.support.support_agent_reports\n",
        "  WHERE user_id = uid\n",
        "  ORDER BY ts DESC\n",
        "  LIMIT 10\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "0c080efe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pip install -U -qqqq typing_extensions dspy-ai mlflow unitycatalog-openai[databricks] openai databricks-sdk databricks-agents pydantic\n",
        "%restart_python"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4777956b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import mlflow\n",
        "import sys\n",
        "from databricks.sdk import WorkspaceClient\n",
        "\n",
        "CATALOG = dbutils.widgets.get(\"CATALOG\")\n",
        "LLM_MODEL = dbutils.widgets.get(\"LLM_MODEL\")\n",
        "SUPPORT_AGENT_ENDPOINT_NAME = dbutils.widgets.get(\"SUPPORT_AGENT_ENDPOINT_NAME\")\n",
        "\n",
        "sys.path.append('../utils')\n",
        "from uc_state import add\n",
        "\n",
        "dev_experiment = mlflow.set_experiment(f\"/Shared/{CATALOG}_support_agent_dev\")\n",
        "add(CATALOG, \"experiments\", {\"experiment_id\": dev_experiment.experiment_id, \"name\": dev_experiment.name})"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4d21e98c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%writefile agent.py\n",
        "import json\n",
        "import warnings\n",
        "from typing import Literal, Optional\n",
        "from uuid import uuid4\n",
        "\n",
        "import dspy\n",
        "import mlflow\n",
        "from mlflow.pyfunc import ResponsesAgent\n",
        "from mlflow.types.responses import ResponsesAgentRequest, ResponsesAgentResponse\n",
        "from pydantic import BaseModel, Field\n",
        "from unitycatalog.ai.core.base import get_uc_function_client\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\".*Ignoring the default notebook Spark session.*\")\n",
        "\n",
        "mlflow.dspy.autolog(log_traces=True)\n",
        "\n",
        "LLM_MODEL = \"{{LLM_MODEL}}\"\n",
        "CATALOG = \"{{CATALOG}}\"\n",
        "\n",
        "lm = dspy.LM(f\"databricks/{LLM_MODEL}\", max_tokens=2000)\n",
        "dspy.configure(lm=lm)\n",
        "uc_client = get_uc_function_client()\n",
        "\n",
        "\n",
        "class SupportReport(BaseModel):\n",
        "    support_request_id: str\n",
        "    user_id: str\n",
        "    order_id: str\n",
        "    credit_recommendation: Optional[dict] = None\n",
        "    refund_recommendation: Optional[dict] = None\n",
        "    draft_response: str\n",
        "    past_interactions_summary: str\n",
        "    order_details_summary: str\n",
        "    decision_confidence: Literal[\"high\", \"medium\", \"low\"] = Field(default=\"medium\")\n",
        "    escalation_flag: bool = Field(default=False)\n",
        "\n",
        "\n",
        "class SupportTriage(dspy.Signature):\n",
        "    \"\"\"Analyze a support request and produce a structured support report.\n",
        "\n",
        "    Use tools to gather order details and user history before deciding on credit/refund recommendations.\n",
        "    If there is not enough evidence, avoid monetary recommendations and set escalation_flag=true.\n",
        "    \"\"\"\n",
        "\n",
        "    support_request: str = dspy.InputField(desc=\"Support request text with support_request_id, user_id, and order_id\")\n",
        "    support_request_id: str = dspy.OutputField()\n",
        "    user_id: str = dspy.OutputField()\n",
        "    order_id: str = dspy.OutputField()\n",
        "    credit_recommendation_json: str = dspy.OutputField(desc=\"JSON object or null\")\n",
        "    refund_recommendation_json: str = dspy.OutputField(desc=\"JSON object or null\")\n",
        "    draft_response: str = dspy.OutputField()\n",
        "    past_interactions_summary: str = dspy.OutputField()\n",
        "    order_details_summary: str = dspy.OutputField()\n",
        "    decision_confidence: str = dspy.OutputField(desc=\"high, medium, low\")\n",
        "    escalation_flag: str = dspy.OutputField(desc=\"true or false\")\n",
        "\n",
        "\n",
        "def get_order_overview(order_id: str) -> str:\n",
        "    return str(uc_client.execute_function(f\"{CATALOG}.ai.get_order_overview\", {\"oid\": order_id}).value)\n",
        "\n",
        "\n",
        "def get_order_timing(order_id: str) -> str:\n",
        "    return str(uc_client.execute_function(f\"{CATALOG}.ai.get_order_timing\", {\"oid\": order_id}).value)\n",
        "\n",
        "\n",
        "def get_user_support_history(user_id: str) -> str:\n",
        "    return str(uc_client.execute_function(f\"{CATALOG}.ai.get_user_support_history\", {\"uid\": user_id}).value)\n",
        "\n",
        "\n",
        "class SupportModule(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.react = dspy.ReAct(\n",
        "            signature=SupportTriage,\n",
        "            tools=[get_order_overview, get_order_timing, get_user_support_history],\n",
        "            max_iters=10,\n",
        "        )\n",
        "\n",
        "    def forward(self, support_request: str) -> SupportReport:\n",
        "        result = self.react(support_request=support_request)\n",
        "\n",
        "        def parse_json_or_none(value: str):\n",
        "            if value is None:\n",
        "                return None\n",
        "            value = str(value).strip()\n",
        "            if value.lower() in {\"\", \"null\", \"none\"}:\n",
        "                return None\n",
        "            try:\n",
        "                return json.loads(value)\n",
        "            except Exception:\n",
        "                return None\n",
        "\n",
        "        escalation = str(result.escalation_flag).strip().lower() in {\"true\", \"1\", \"yes\"}\n",
        "        conf = str(result.decision_confidence).strip().lower()\n",
        "        if conf not in {\"high\", \"medium\", \"low\"}:\n",
        "            conf = \"medium\"\n",
        "\n",
        "        return SupportReport(\n",
        "            support_request_id=str(result.support_request_id),\n",
        "            user_id=str(result.user_id),\n",
        "            order_id=str(result.order_id),\n",
        "            credit_recommendation=parse_json_or_none(result.credit_recommendation_json),\n",
        "            refund_recommendation=parse_json_or_none(result.refund_recommendation_json),\n",
        "            draft_response=str(result.draft_response),\n",
        "            past_interactions_summary=str(result.past_interactions_summary),\n",
        "            order_details_summary=str(result.order_details_summary),\n",
        "            decision_confidence=conf,\n",
        "            escalation_flag=escalation,\n",
        "        )\n",
        "\n",
        "\n",
        "class DSPySupportAgent(ResponsesAgent):\n",
        "    def __init__(self):\n",
        "        self.module = SupportModule()\n",
        "\n",
        "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
        "        user_message = None\n",
        "        for msg in request.input:\n",
        "            msg_dict = msg.model_dump() if hasattr(msg, \"model_dump\") else msg\n",
        "            if msg_dict.get(\"role\") == \"user\":\n",
        "                user_message = msg_dict.get(\"content\", \"\")\n",
        "                break\n",
        "        if not user_message:\n",
        "            raise ValueError(\"No user message found\")\n",
        "\n",
        "        result = self.module(support_request=user_message)\n",
        "        return ResponsesAgentResponse(\n",
        "            output=[self.create_text_output_item(text=result.model_dump_json(), id=str(uuid4()))],\n",
        "            custom_outputs=request.custom_inputs,\n",
        "        )\n",
        "\n",
        "\n",
        "AGENT = DSPySupportAgent()\n",
        "mlflow.models.set_model(AGENT)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "2c42256c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import textwrap\n",
        "\n",
        "agent_source = textwrap.dedent(f'''\n",
        "import json\n",
        "import warnings\n",
        "from typing import Literal, Optional\n",
        "from uuid import uuid4\n",
        "\n",
        "import dspy\n",
        "import mlflow\n",
        "from mlflow.pyfunc import ResponsesAgent\n",
        "from mlflow.types.responses import ResponsesAgentRequest, ResponsesAgentResponse\n",
        "from pydantic import BaseModel, Field\n",
        "from unitycatalog.ai.core.base import get_uc_function_client\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\".*Ignoring the default notebook Spark session.*\")\n",
        "\n",
        "mlflow.dspy.autolog(log_traces=True)\n",
        "\n",
        "LLM_MODEL = \"{LLM_MODEL}\"\n",
        "CATALOG = \"{CATALOG}\"\n",
        "\n",
        "lm = dspy.LM(f\"databricks/{{LLM_MODEL}}\", max_tokens=2000)\n",
        "dspy.configure(lm=lm)\n",
        "uc_client = get_uc_function_client()\n",
        "\n",
        "\n",
        "class SupportReport(BaseModel):\n",
        "    support_request_id: str\n",
        "    user_id: str\n",
        "    order_id: str\n",
        "    credit_recommendation: Optional[dict] = None\n",
        "    refund_recommendation: Optional[dict] = None\n",
        "    draft_response: str\n",
        "    past_interactions_summary: str\n",
        "    order_details_summary: str\n",
        "    decision_confidence: Literal[\"high\", \"medium\", \"low\"] = Field(default=\"medium\")\n",
        "    escalation_flag: bool = Field(default=False)\n",
        "\n",
        "\n",
        "class SupportTriage(dspy.Signature):\n",
        "    \"\"\"Analyze a support request and produce a structured support report.\"\"\"\n",
        "\n",
        "    support_request: str = dspy.InputField(desc=\"Support request text with support_request_id, user_id, and order_id\")\n",
        "    support_request_id: str = dspy.OutputField()\n",
        "    user_id: str = dspy.OutputField()\n",
        "    order_id: str = dspy.OutputField()\n",
        "    credit_recommendation_json: str = dspy.OutputField(desc=\"JSON object or null\")\n",
        "    refund_recommendation_json: str = dspy.OutputField(desc=\"JSON object or null\")\n",
        "    draft_response: str = dspy.OutputField()\n",
        "    past_interactions_summary: str = dspy.OutputField()\n",
        "    order_details_summary: str = dspy.OutputField()\n",
        "    decision_confidence: str = dspy.OutputField(desc=\"high, medium, low\")\n",
        "    escalation_flag: str = dspy.OutputField(desc=\"true or false\")\n",
        "\n",
        "\n",
        "def get_order_overview(order_id: str) -> str:\n",
        "    return str(uc_client.execute_function(f\"{{CATALOG}}.ai.get_order_overview\", {{\"oid\": order_id}}).value)\n",
        "\n",
        "\n",
        "def get_order_timing(order_id: str) -> str:\n",
        "    return str(uc_client.execute_function(f\"{{CATALOG}}.ai.get_order_timing\", {{\"oid\": order_id}}).value)\n",
        "\n",
        "\n",
        "def get_user_support_history(user_id: str) -> str:\n",
        "    return str(uc_client.execute_function(f\"{{CATALOG}}.ai.get_user_support_history\", {{\"uid\": user_id}}).value)\n",
        "\n",
        "\n",
        "class SupportModule(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.react = dspy.ReAct(\n",
        "            signature=SupportTriage,\n",
        "            tools=[get_order_overview, get_order_timing, get_user_support_history],\n",
        "            max_iters=10,\n",
        "        )\n",
        "\n",
        "    def forward(self, support_request: str) -> SupportReport:\n",
        "        result = self.react(support_request=support_request)\n",
        "\n",
        "        def parse_json_or_none(value: str):\n",
        "            if value is None:\n",
        "                return None\n",
        "            value = str(value).strip()\n",
        "            if value.lower() in {{\"\", \"null\", \"none\"}}:\n",
        "                return None\n",
        "            try:\n",
        "                return json.loads(value)\n",
        "            except Exception:\n",
        "                return None\n",
        "\n",
        "        escalation = str(result.escalation_flag).strip().lower() in {{\"true\", \"1\", \"yes\"}}\n",
        "        conf = str(result.decision_confidence).strip().lower()\n",
        "        if conf not in {{\"high\", \"medium\", \"low\"}}:\n",
        "            conf = \"medium\"\n",
        "\n",
        "        return SupportReport(\n",
        "            support_request_id=str(result.support_request_id),\n",
        "            user_id=str(result.user_id),\n",
        "            order_id=str(result.order_id),\n",
        "            credit_recommendation=parse_json_or_none(result.credit_recommendation_json),\n",
        "            refund_recommendation=parse_json_or_none(result.refund_recommendation_json),\n",
        "            draft_response=str(result.draft_response),\n",
        "            past_interactions_summary=str(result.past_interactions_summary),\n",
        "            order_details_summary=str(result.order_details_summary),\n",
        "            decision_confidence=conf,\n",
        "            escalation_flag=escalation,\n",
        "        )\n",
        "\n",
        "\n",
        "class DSPySupportAgent(ResponsesAgent):\n",
        "    def __init__(self):\n",
        "        self.module = SupportModule()\n",
        "\n",
        "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
        "        user_message = None\n",
        "        for msg in request.input:\n",
        "            msg_dict = msg.model_dump() if hasattr(msg, \"model_dump\") else msg\n",
        "            if msg_dict.get(\"role\") == \"user\":\n",
        "                user_message = msg_dict.get(\"content\", \"\")\n",
        "                break\n",
        "        if not user_message:\n",
        "            raise ValueError(\"No user message found\")\n",
        "\n",
        "        result = self.module(support_request=user_message)\n",
        "        return ResponsesAgentResponse(\n",
        "            output=[self.create_text_output_item(text=result.model_dump_json(), id=str(uuid4()))],\n",
        "            custom_outputs=request.custom_inputs,\n",
        "        )\n",
        "\n",
        "\n",
        "AGENT = DSPySupportAgent()\n",
        "mlflow.models.set_model(AGENT)\n",
        "''')\n",
        "\n",
        "with open(\"agent.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(agent_source)\n",
        "\n",
        "print(\"Wrote agent.py with concrete CATALOG/LLM_MODEL values\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "14e836ea"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import mlflow\n",
        "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
        "\n",
        "sample = spark.sql(f\"SELECT support_request_id, user_id, order_id, request_text FROM {CATALOG}.support.raw_support_requests LIMIT 1\").collect()\n",
        "if sample:\n",
        "    row = sample[0]\n",
        "    msg = f\"support_request_id={row['support_request_id']} user_id={row['user_id']} order_id={row['order_id']} text={row['request_text']}\"\n",
        "else:\n",
        "    msg = \"support_request_id=sample-1 user_id=user-1 order_id=order-1 text=My delivery was late and items were missing.\"\n",
        "\n",
        "resources = [DatabricksServingEndpoint(endpoint_name=LLM_MODEL)]\n",
        "for fn in [f\"{CATALOG}.ai.get_order_overview\", f\"{CATALOG}.ai.get_order_timing\", f\"{CATALOG}.ai.get_user_support_history\"]:\n",
        "    resources.append(DatabricksFunction(function_name=fn))\n",
        "\n",
        "input_example = {\"input\": [{\"role\": \"user\", \"content\": msg}]}\n",
        "\n",
        "with mlflow.start_run():\n",
        "    logged_agent_info = mlflow.pyfunc.log_model(\n",
        "        name=\"support_agent\",\n",
        "        python_model=\"agent.py\",\n",
        "        input_example=input_example,\n",
        "        resources=resources,\n",
        "    )\n",
        "\n",
        "mlflow.set_active_model(model_id=logged_agent_info.model_id)\n",
        "mlflow.set_registry_uri(\"databricks-uc\")\n",
        "UC_MODEL_NAME = f\"{CATALOG}.ai.support_agent\"\n",
        "uc_registered_model_info = mlflow.register_model(model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ed761f74"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import mlflow\n",
        "import time\n",
        "from databricks import agents\n",
        "from databricks.sdk import WorkspaceClient\n",
        "from databricks.sdk.service.serving import EndpointStateReady\n",
        "\n",
        "prod_experiment = mlflow.set_experiment(f\"/Shared/{CATALOG}_support_agent_prod\")\n",
        "add(CATALOG, \"experiments\", {\"experiment_id\": prod_experiment.experiment_id, \"name\": prod_experiment.name})\n",
        "\n",
        "deployment_info = agents.deploy(\n",
        "    model_name=UC_MODEL_NAME,\n",
        "    model_version=uc_registered_model_info.version,\n",
        "    scale_to_zero=False,\n",
        "    endpoint_name=SUPPORT_AGENT_ENDPOINT_NAME,\n",
        "    environment_vars={\"MLFLOW_EXPERIMENT_ID\": str(prod_experiment.experiment_id)},\n",
        ")\n",
        "\n",
        "workspace = WorkspaceClient()\n",
        "ready = False\n",
        "for _ in range(90):\n",
        "    endpoint = workspace.serving_endpoints.get(name=SUPPORT_AGENT_ENDPOINT_NAME)\n",
        "    if endpoint.state and endpoint.state.ready == EndpointStateReady.READY:\n",
        "        ready = True\n",
        "        break\n",
        "    time.sleep(10)\n",
        "\n",
        "if not ready:\n",
        "    raise RuntimeError(f\"Endpoint {SUPPORT_AGENT_ENDPOINT_NAME} did not reach READY within polling window\")\n",
        "\n",
        "add(CATALOG, \"endpoints\", deployment_info)\n",
        "print(f\"Endpoint {SUPPORT_AGENT_ENDPOINT_NAME} is READY\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "bb160c06"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}