{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Support Lakebase (v2 autoscaling)\n",
        "\n",
        "Provision a Lakebase v2 project/branch/endpoint and sync support + credit recommendation data from lakehouse."
      ],
      "id": "e73bba9e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pip install --upgrade databricks-sdk psycopg2-binary\n",
        "%restart_python"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "300f6ff0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import re\n",
        "import time\n",
        "from databricks.sdk import WorkspaceClient\n",
        "from databricks.sdk.service.postgres import Project, ProjectSpec\n",
        "\n",
        "CATALOG = dbutils.widgets.get(\"CATALOG\")\n",
        "w = WorkspaceClient()\n",
        "\n",
        "safe = re.sub(r\"[^a-z0-9-]\", \"-\", CATALOG.lower())\n",
        "safe = re.sub(r\"-+\", \"-\", safe).strip(\"-\")\n",
        "if not safe:\n",
        "    safe = \"support\"\n",
        "\n",
        "project_id = f\"{safe}-support-db\"\n",
        "project_name = f\"projects/{project_id}\"\n",
        "\n",
        "try:\n",
        "    project = w.postgres.get_project(project_name)\n",
        "except Exception:\n",
        "    op = w.postgres.create_project(\n",
        "        project_id=project_id,\n",
        "        project=Project(spec=ProjectSpec(display_name=f\"{CATALOG}-support-db\")),\n",
        "    )\n",
        "    project = op.wait()\n",
        "\n",
        "branches = list(w.postgres.list_branches(parent=project_name))\n",
        "default_branch = next((b for b in branches if getattr(getattr(b, \"status\", None), \"default\", False)), branches[0])\n",
        "branch_name = default_branch.name\n",
        "\n",
        "endpoints = list(w.postgres.list_endpoints(parent=branch_name))\n",
        "if endpoints:\n",
        "    endpoint = next((e for e in endpoints if str(getattr(getattr(e, \"status\", None), \"endpoint_type\", \"\")).endswith(\"READ_WRITE\")), endpoints[0])\n",
        "else:\n",
        "    # Should normally exist by default; wait and retry a few times before hard fail.\n",
        "    endpoint = None\n",
        "    for _ in range(12):\n",
        "        time.sleep(5)\n",
        "        endpoints = list(w.postgres.list_endpoints(parent=branch_name))\n",
        "        if endpoints:\n",
        "            endpoint = endpoints[0]\n",
        "            break\n",
        "    if endpoint is None:\n",
        "        raise RuntimeError(\"No Lakebase v2 endpoint found for support-db project\")\n",
        "\n",
        "endpoint_name = endpoint.name\n",
        "endpoint_host = endpoint.status.hosts.host\n",
        "print(f\"Project: {project_name}\")\n",
        "print(f\"Branch: {branch_name}\")\n",
        "print(f\"Endpoint: {endpoint_name}\")\n",
        "print(f\"Host: {endpoint_host}\")\n",
        "\n",
        "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.support\")\n",
        "spark.sql(f\"\"\"\n",
        "CREATE OR REPLACE TABLE {CATALOG}.support.lakebase_v2_config (\n",
        "  updated_at TIMESTAMP,\n",
        "  project_name STRING,\n",
        "  branch_name STRING,\n",
        "  endpoint_name STRING,\n",
        "  endpoint_host STRING,\n",
        "  database_name STRING\n",
        ")\n",
        "\"\"\")\n",
        "spark.sql(\n",
        "    f\"\"\"\n",
        "    INSERT OVERWRITE {CATALOG}.support.lakebase_v2_config\n",
        "    SELECT current_timestamp(), '{project_name}', '{branch_name}', '{endpoint_name}', '{endpoint_host}', 'databricks_postgres'\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "import sys\n",
        "sys.path.append('../utils')\n",
        "from uc_state import add\n",
        "\n",
        "add(CATALOG, \"databaseinstances\", {\"name\": project_name, \"type\": \"lakebase_v2_project\"})\n",
        "add(CATALOG, \"databasecatalogs\", {\"name\": branch_name, \"type\": \"lakebase_v2_branch\"})\n",
        "add(CATALOG, \"pipelines\", {\"pipeline_id\": endpoint_name, \"type\": \"lakebase_v2_endpoint\"})"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "a6bb5572"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import psycopg2\n",
        "\n",
        "creds = w.postgres.generate_database_credential(endpoint=endpoint_name)\n",
        "current_user = w.current_user.me().user_name\n",
        "password = creds.token\n",
        "\n",
        "conn = psycopg2.connect(\n",
        "    host=endpoint_host,\n",
        "    port=5432,\n",
        "    dbname=\"databricks_postgres\",\n",
        "    user=current_user,\n",
        "    password=password,\n",
        "    sslmode=\"require\",\n",
        ")\n",
        "conn.autocommit = False\n",
        "\n",
        "with conn.cursor() as cur:\n",
        "    cur.execute(\"CREATE SCHEMA IF NOT EXISTS support\")\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS support.operator_actions (\n",
        "          action_id BIGSERIAL PRIMARY KEY,\n",
        "          support_request_id TEXT NOT NULL,\n",
        "          order_id TEXT NOT NULL,\n",
        "          user_id TEXT,\n",
        "          action_type TEXT NOT NULL CHECK (action_type IN ('apply_refund','apply_credit','send_reply')),\n",
        "          amount_usd NUMERIC(10,2),\n",
        "          payload JSONB,\n",
        "          status TEXT NOT NULL DEFAULT 'recorded',\n",
        "          actor TEXT,\n",
        "          created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS support.support_replies (\n",
        "          reply_id BIGSERIAL PRIMARY KEY,\n",
        "          support_request_id TEXT NOT NULL,\n",
        "          order_id TEXT NOT NULL,\n",
        "          user_id TEXT,\n",
        "          message_text TEXT NOT NULL,\n",
        "          sent_by TEXT,\n",
        "          created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS support.request_status (\n",
        "          support_request_id TEXT PRIMARY KEY,\n",
        "          status TEXT NOT NULL DEFAULT 'pending',\n",
        "          assigned_to TEXT,\n",
        "          updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n",
        "          last_action TEXT,\n",
        "          notes TEXT\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Synced support report tables are managed externally (UC synced table),\n",
        "    # so this stage only provisions app-owned operational tables.\n",
        "\n",
        "    conn.commit()\n",
        "\n",
        "conn.close()\n",
        "print(\"Support Lakebase v2 provisioning complete\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "92835191"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}